{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Peformance Analysis\n",
    "#  After having played with the data and using sophisticated algorithms, you finally develop a model.\n",
    "#  But how to analyse and evaluate and rate the performance of your model.\n",
    "#  There are various performance metrics depending on the type of your problem(classification,regression,etc.)\n",
    "#  We look into some important figure of merits for a classification(binary) model.\n",
    "###################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as measr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Example Model</h3>\n",
    "Take a quick glance at the example model and get the gist. It is not important to understand the model completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "29.69911764705882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Example Model ###\n",
    "### Titanic Dataset : Binary classification on the chance of survival given passenger details ###\n",
    "### Get the dataset on https://www.kaggle.com/c/titanic/data \n",
    "### Model : Logistic Regression \n",
    "train_data = pd.read_csv(\"Downloads/train.csv\")\n",
    "print(train_data.shape)\n",
    "train_data.head()\n",
    "# Reassigning male and female string to more 'modellable' values\n",
    "for i in range(train_data.shape[0]):\n",
    "    if(train_data['Sex'][i] == 'male'):\n",
    "        train_data['Sex'].values[i] = '0'\n",
    "    if(train_data['Sex'][i] == 'female'):\n",
    "        train_data['Sex'].values[i] = '1'\n",
    "train_data.head()\n",
    "mean = train_data['Age'].mean(axis = 0, skipna = True)\n",
    "print(mean)\n",
    "#Reassigning the NaN values in Age with the mean of the ages\n",
    "for i in range(train_data.shape[0]):\n",
    "    if(pd.isnull(train_data['Age'][i]) == True):\n",
    "        train_data['Age'].values[i] = mean\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 891) (891,)\n",
      "(418, 2)\n"
     ]
    }
   ],
   "source": [
    "#Isolating trainable features\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "X_train = np.array([train_data['Pclass'].values, train_data['Age'].values, train_data['SibSp'].values, train_data['Parch'].values, train_data['Sex'].values])\n",
    "Y_train = np.array(train_data['Survived'].values)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "\n",
    "#Scikit Learn's Logistic Regression Model \n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train.T, Y_train)\n",
    "\n",
    "#Preprocessing test data\n",
    "test_data = pd.read_csv(\"Downloads/test.csv\")\n",
    "for i in range(test_data.shape[0]):\n",
    "    if(test_data['Sex'][i] == 'male'):\n",
    "        test_data['Sex'].values[i] = '0'\n",
    "    if(test_data['Sex'][i] == 'female'):\n",
    "        test_data['Sex'].values[i] = '1'\n",
    "meant = test_data['Age'].mean(axis = 0, skipna = True)\n",
    "for i in range(test_data.shape[0]):\n",
    "    if(pd.isnull(test_data['Age'][i]) == True):\n",
    "        test_data['Age'].values[i] = meant\n",
    "X_test = np.array([test_data['Pclass'].values, test_data['Age'].values, test_data['SibSp'].values, test_data['Parch'].values, test_data['Sex'].values])\n",
    "#the model predicted values\n",
    "Y_pred = logReg.predict(X_test.T)\n",
    "\n",
    "#the actual test values\n",
    "ans_key = pd.read_csv(\"Downloads/submission.csv\")\n",
    "print(ans_key.shape)\n",
    "ans_key.head()\n",
    "Y_test = ans_key['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Outcomes and Confusion Matrix</h3>\n",
    "\n",
    "<p>For a binary classification algorithm, the prediction by the model on a test data example can relate to the actual outcome in one of the following ways :</p> \n",
    " <ol>\n",
    "   <li> Actual : 1, Predicted : 1 --- True Positive TP\n",
    "   <li> Actual : 0, Predicted : 1 --- False Postive FP\n",
    "   <li> Actual : 1, Predicted : 0 --- False Negative FN\n",
    "   <li> Actual : 0, Predicted : 0 --- True Negative TN\n",
    " </ol>\n",
    " <p>The number of TPs, FPs, TNs and FNs are counted for the entire set. We compile these results in a tabular form in the CONFUSION MATRIX.</p>\n",
    " <table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Pred.</th>\n",
    "            <th>0</th>\n",
    "            <th>1</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>Actual</th>\n",
    "            <th> </th>\n",
    "            <th> </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> \n",
    "            <th>0</th>\n",
    "            <td>#TN</td>\n",
    "            <td>#FP</td>\n",
    "        </tr>\n",
    "        <tr> \n",
    "            <th>1</th>\n",
    "            <td>#FN</td>\n",
    "            <td>#TP</td>\n",
    "        </tr>\n",
    "    </tbody> \n",
    " </table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 52\n",
      "50 108\n",
      "[[208  52]\n",
      " [ 50 108]]\n"
     ]
    }
   ],
   "source": [
    "#Manual Computation of Confusion Matrix\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(ans_key.shape[0]):\n",
    "    if(Y_pred[i] == 1 and ans_key['Survived'][i] == 1):\n",
    "        tp+=1\n",
    "    if(Y_pred[i] == 1 and ans_key['Survived'][i] == 0):\n",
    "        fp+=1\n",
    "    if(Y_pred[i] == 0 and ans_key['Survived'][i] == 1):\n",
    "        fn+=1\n",
    "    if(Y_pred[i] == 0 and ans_key['Survived'][i] == 0):\n",
    "        tn+=1\n",
    "print(tn, fp)\n",
    "print(fn, tp)\n",
    "\n",
    "#Using sklearn's confusion_matrix\n",
    "print(measr.confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Evaluation Metrics - Accuracy, Precision & Recall</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p>Now that we have the confusion matrix ready, we will look into precision and recall, some important model evaluation metrics.</p>\n",
    "\n",
    "\n",
    " (1) <b>Accuracy</b> is simply the ratio of all correctly classified examples to all the examples. The accuracy measure is intuitive as good estimate of the performance of the model but it is not suited for an imbalanced classification problem which are quite common in everyday applications.\n",
    " \n",
    " $$\n",
    " Accuracy = \\frac{True Positives(TP) + True Negatives(TN)}{True Positives(TP) + True Negatives(TN) + False Positives(FP) + False Negatives(TN)}\n",
    " $$\n",
    "   <br>For example, if we have a spam classifier or a disease detection model where the disease rate is low. Suppose in such a problem we may get one or two spam mails or one or two postive patients as opposed to the hundreds of important mails we get or thousands of patients we scan for the disease. \n",
    "   <br>In such a case simple accuracy calculation is not a good evaluation strategy since we can get around 95-99% accuracy if we simply label every email as not spam or every patient as negative. But in these problems the positive example space is largely undermined by the more numerous negative examples, however we are more concerned with the performance on postive examples while the accuracy evaluation does not provide any insight into the problem. We turn to a more positive-example emphasizing measures of performance.\n",
    " \n",
    " \n",
    " (2) <b>Recall</b> is the ratio of the correctly identified positives to all the actual postives. It is the measure of the ability of the model to identify all the positive examples.\n",
    " \n",
    " $$\n",
    " Recall = \\frac{True Positives(TP)}{True Positives(TP) + False Negatives(FN)}\n",
    " $$\n",
    "<br>A recall value close to 1.00 is an indicator that the model identifies all the positive examples. But there is a caveat, if we know label each email as spam or each patient as diseased then we get a recall of 1 since we never a positive but the model is not actually classifying. By this reasoning we understand that maximizing recall alone cannot guarantee a good classifier. \n",
    "\n",
    " (3) <b>Precision</b> is the ratio of the correctly classified positive examples to all the examples that are either correctly or incorrectly classified as positives. \n",
    " \n",
    " $$\n",
    " Precision = \\frac{True Positives(TP)}{True Positives(TP) + False Positives(FP)}\n",
    " $$\n",
    " <br>The precision value is actually a measure of the ability of the model to correctly identify only the positive examples in the dataset. Together with recall, we can judge the performance of a classifier.\n",
    " <br>In other words, high precision guarantees that no negative examples will be flagged positive while a high recall guarantees all the positive examples will be flagged positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7559808612440191\n",
      "recall :  0.6835443037974683\n",
      "precision :  0.675\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(\"accuracy : \", accuracy)\n",
    "#recall\n",
    "recall = tp/(tp+fn)\n",
    "print(\"recall : \", recall)\n",
    "#precision\n",
    "precision = tp/(tp+fp)\n",
    "print(\"precision : \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7559808612440191\n",
      "recall :  0.6835443037974683\n",
      "precision :  0.675\n"
     ]
    }
   ],
   "source": [
    "# There are library functions in sklearn for precision, recall\n",
    "print(\"accuracy : \", measr.accuracy_score(Y_test, Y_pred))\n",
    "print(\"recall : \", measr.recall_score(Y_test, Y_pred))\n",
    "print(\"precision : \", measr.precision_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Precision-Recall Tradeoff and F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It is easy to see that our goal is a high precision-high recall model, that is, a model that correctly identifes all positives examples while not misjudging any negative example. This goal now prevents the earlier model where we flagged every mail as spam and every patient as diseased, since this model has a very low precision though the recall is high.</p>\n",
    "<p>Now on the contrary lets imagine a model that identifies just one positive example correctly. This has a high precision of 1.00 since it has not mislabelled any example as positive but it surely has missed a lot of positive examples and hence its recall is low.</p>\n",
    "<p>This is the crux of the <b>precision-recall tradeoff</b> that is observed very often in practice.\n",
    "Whether to emphasize more on high precision or high recall is dependent on the application an the result we desire. For example in the disease detection problem we may desire that no positive(diseased person) is left out and so we may focus on a high recall model than a precision model that misses out a few positve examples. In a spam classifier we may want a high precision model so that the user may not miss any important mail that was misclassified as a positive(spam) than a high recall model that classifies every spam email but may also classify your acceptance letter as spam ;(</p>\n",
    "<p>Most of the times, the problem may not require extremely high recall or precision, but a balanced maximization of both of them, we combine the two figures in a single performance metric called the <b>F1 Score</b>.</p>\n",
    "\n",
    "$$\n",
    "F1\\ Score = 2\\cdot\\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$\n",
    "<p>The F1 Score is the harmonic mean of the precision and recall that gives equal weightage to both precision and recall values and the modified goal is to maximize the F1 Score. The harmonic mean penalizes the extreme cases like precision = 1 and recall = 0 and vice versa, thus giving a balanced evaluation metric.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score(formulae) :  0.679245283018868\n",
      "F1 Score(sklearn) :  0.679245283018868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fa3b21b6820>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#f1 score\n",
    "print(\"F1 Score(formulae) : \", (2 * precision * recall)/(precision + recall))\n",
    "# From sklearn.metrics library function\n",
    "print(\"F1 Score(sklearn) : \", measr.f1_score(Y_test, Y_pred))\n",
    "## An example of how precision and recall varies with respect to each other\n",
    "## where the tradeoff can be easily visualised.\n",
    "measr.plot_precision_recall_curve(logReg, X_test.T, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       260\n",
      "           1       0.68      0.68      0.68       158\n",
      "\n",
      "    accuracy                           0.76       418\n",
      "   macro avg       0.74      0.74      0.74       418\n",
      "weighted avg       0.76      0.76      0.76       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#everything in one go\n",
    "print(measr.classification_report(Y_test,Y_pred))\n",
    "##note: in the classification_report output there is precision and recall consider both 0 and 1 as a positive examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Precision and Recall in Multiclass Classification</h3>\n",
    "\n",
    "<p>The above definitions have been limited to a binary classifier model, but we can easily extend the definition of each of the above to a multiclass classifier model. We take an example of a 4-class classifier{0,1,2,3}</p>\n",
    "\n",
    "<p>The confusion matrix is then defined as $4\\times 4$ matrix $A = [a_{ij}]$ where $a_{ij}$ denotes the number of cases where the predicted class was i but the actual class was j where both $i,j\\in \\{0,1,2,3\\}$</p>\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Pred.</th>\n",
    "            <th>$0$</th>\n",
    "            <th>$1$</th>\n",
    "            <th>$2$</th>\n",
    "            <th>$3$</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>Actual</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> \n",
    "            <th>$0$</th>\n",
    "            <td>$a_{00}$</td>\n",
    "            <td>$a_{10}$</td>\n",
    "            <td>$a_{20}$</td>\n",
    "            <td>$a_{30}$</td>\n",
    "        </tr>\n",
    "        <tr> \n",
    "            <th>$1$</th>\n",
    "            <td>$a_{01}$</td>\n",
    "            <td>$a_{11}$</td>\n",
    "            <td>$a_{21}$</td>\n",
    "            <td>$a_{31}$</td>\n",
    "        </tr>\n",
    "         <tr> \n",
    "            <th>$2$</th>\n",
    "            <td>$a_{02}$</td>\n",
    "            <td>$a_{12}$</td>\n",
    "            <td>$a_{22}$</td>\n",
    "            <td>$a_{32}$</td>\n",
    "        </tr>\n",
    "         <tr> \n",
    "            <th>$3$</th>\n",
    "            <td>$a_{03}$</td>\n",
    "            <td>$a_{13}$</td>\n",
    "            <td>$a_{23}$</td>\n",
    "            <td>$a_{33}$</td>\n",
    "        </tr>\n",
    "    </tbody> \n",
    " </table> \n",
    " \n",
    "<p>Now we can define accuracy, recall and precision as a simple extension of the definitions we used above,\n",
    "<ul>\n",
    "    <li> Accuracy - truly identified examples divided by the total number of examples.\n",
    "    <li> Recall - ratio of truly identified positive examples (say category 0) to the actual number of category 0 examples.\n",
    "    <li> Precision - ratio of truly identified positive examples (category 0) to the all the predicted positives(category 0, here).\n",
    "</ul>\n",
    "$$\n",
    "Accuracy = \\frac{\\sum_{i=0}^{3} a_{ii}}{\\sum_{0\\leq i,j\\leq 3} a_{ij}}\n",
    "$$\n",
    "\n",
    "Note that any class can be considered as a positive example and precision and recall can be calculated from the confusion matrix.\n",
    "<p> For example, considering 0 as the positive class we can write the formulae for precision and recall as :</p>\n",
    "<hr>\n",
    "$$\n",
    "Recall = \\frac{a_{00}}{\\sum_{i=0}^{3} a_{i0}}\n",
    "$$\n",
    "<hr>\n",
    "$$\n",
    "Precision = \\frac{a_{00}}{\\sum_{i=0}^{3} a_{0i}}\n",
    "$$\n",
    "\n",
    "An easy way to get precision and recall is to print the classification report using the above sklearn.metrics function <em>classification_report</em> which calculates the values considering each class a positive turn by turn and then consider the actual positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
