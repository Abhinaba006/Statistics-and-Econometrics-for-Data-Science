{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Peformance Analysis\n",
    "#  After having played with the data and using sophisticated algorithms, you finally develop a model.\n",
    "#  But how to analyse and evaluate and rate the performance of your model.\n",
    "#  There are various performance metrics depending on the type of your problem(classification,regression,etc.)\n",
    "#  We look into some important figure of merits for a classification(binary) model.\n",
    "###################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as measr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>0. Example Model</h3>\n",
    "Take a quick glance at the example model and get the gist. It is not important to understand the model completely. To learn more refer to the logistic regression notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example Model<br>\n",
    "Titanic Dataset : Binary classification on the chance of survival given passenger details<br>\n",
    "Get the dataset on https://www.kaggle.com/c/titanic/data <br>\n",
    "Model : Logistic Regression<br></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the training data\n",
    "train_data = pd.read_csv(\"Downloads/train.csv\")\n",
    "print(train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reassigning male and female string to more 'modellable' values\n",
    "for i in range(train_data.shape[0]):\n",
    "    if(train_data['Sex'][i] == 'male'):\n",
    "        train_data['Sex'].values[i] = '0'\n",
    "    if(train_data['Sex'][i] == 'female'):\n",
    "        train_data['Sex'].values[i] = '1'\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry   0  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate mean of the ages and fares to fill the NaN values\n",
    "mean = train_data['Age'].mean(axis = 0, skipna = True)\n",
    "mean_F = train_data['Fare'].mean(axis = 0, skipna = True)\n",
    "print(mean)\n",
    "#Reassigning the NaN values in Age with the mean of the ages\n",
    "for i in range(train_data.shape[0]):\n",
    "    if(pd.isnull(train_data['Age'][i]) == True):\n",
    "        train_data['Age'].values[i] = mean\n",
    "    if(pd.isnull(train_data['Fare'][i]) == True):\n",
    "        train_data['Fare'].values[i] = mean_F\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 891) (891,)\n"
     ]
    }
   ],
   "source": [
    "#Isolating trainable features\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n",
    "X_train = np.array([train_data['Pclass'].values, train_data['Age'].values, train_data['SibSp'].values, train_data['Parch'].values, train_data['Sex'].values, train_data['Fare'].values])\n",
    "Y_train = np.array(train_data['Survived'].values)\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scikit Learn's Logistic Regression Model\n",
    "logReg = LogisticRegression()\n",
    "#Fit the model to training data\n",
    "logReg.fit(X_train.T, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name Sex  \\\n",
       "0          892       3                              Kelly, Mr. James   0   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
       "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
       "3          895       3                              Wirz, Mr. Albert   0   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading test data\n",
    "test_data = pd.read_csv(\"Downloads/test.csv\")\n",
    "\n",
    "#Reassigning male - 0, female - 1 similar to that in train data\n",
    "for i in range(test_data.shape[0]):\n",
    "    if(test_data['Sex'][i] == 'male'):\n",
    "        test_data['Sex'].values[i] = '0'\n",
    "    if(test_data['Sex'][i] == 'female'):\n",
    "        test_data['Sex'].values[i] = '1'\n",
    "        \n",
    "#Replace NaN in the test data with the mean \n",
    "meant = test_data['Age'].mean(axis = 0, skipna = True)\n",
    "meanf = test_data['Fare'].mean(axis = 0, skipna = True)\n",
    "for i in range(test_data.shape[0]):\n",
    "    if(pd.isnull(test_data['Age'][i]) == True):\n",
    "        test_data['Age'].values[i] = meant\n",
    "    if(pd.isnull(test_data['Fare'][i]) == True):\n",
    "        test_data['Fare'].values[i] = meanf\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 2)\n"
     ]
    }
   ],
   "source": [
    "#Isolating the same features as train data from the test data\n",
    "X_test = np.array([test_data['Pclass'].values, test_data['Age'].values, test_data['SibSp'].values, test_data['Parch'].values, test_data['Sex'].values, test_data['Fare'].values])\n",
    "\n",
    "#Using the trained model to predict values for the above isolate test data\n",
    "Y_pred = logReg.predict(X_test.T)##Predicted Values\n",
    "\n",
    "#Load the actual test values\n",
    "ans_key = pd.read_csv(\"Downloads/submission.csv\")\n",
    "print(ans_key.shape)\n",
    "ans_key.head()\n",
    "Y_test = ans_key['Survived'].values##Actual Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Outcomes and Confusion Matrix</h3>\n",
    "\n",
    "<p>For a binary classification algorithm, the prediction by the model on a test data example can relate to the actual outcome in one of the following ways :</p> \n",
    " <ol>\n",
    "   <li> Actual : 1, Predicted : 1 --- True Positive TP\n",
    "   <li> Actual : 0, Predicted : 1 --- False Postive FP\n",
    "   <li> Actual : 1, Predicted : 0 --- False Negative FN\n",
    "   <li> Actual : 0, Predicted : 0 --- True Negative TN\n",
    " </ol>\n",
    " <p>The number of TPs, FPs, TNs and FNs are counted for the entire set. We compile these results in a tabular form in the CONFUSION MATRIX.</p>\n",
    " <table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Pred.</th>\n",
    "            <th>0</th>\n",
    "            <th>1</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>Actual</th>\n",
    "            <th> </th>\n",
    "            <th> </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> \n",
    "            <th>0</th>\n",
    "            <td>#TN</td>\n",
    "            <td>#FP</td>\n",
    "        </tr>\n",
    "        <tr> \n",
    "            <th>1</th>\n",
    "            <td>#FN</td>\n",
    "            <td>#TP</td>\n",
    "        </tr>\n",
    "    </tbody> \n",
    " </table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211 49\n",
      "52 106\n",
      "[[211  49]\n",
      " [ 52 106]]\n"
     ]
    }
   ],
   "source": [
    "#Manual Computation of Confusion Matrix\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "for i in range(ans_key.shape[0]):\n",
    "    if(Y_pred[i] == 1 and ans_key['Survived'][i] == 1):\n",
    "        tp+=1\n",
    "    if(Y_pred[i] == 1 and ans_key['Survived'][i] == 0):\n",
    "        fp+=1\n",
    "    if(Y_pred[i] == 0 and ans_key['Survived'][i] == 1):\n",
    "        fn+=1\n",
    "    if(Y_pred[i] == 0 and ans_key['Survived'][i] == 0):\n",
    "        tn+=1\n",
    "print(tn, fp)\n",
    "print(fn, tp)\n",
    "\n",
    "#Using sklearn's confusion_matrix\n",
    "print(measr.confusion_matrix(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Evaluation Metrics - Accuracy, Precision & Recall</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <p>Now that we have the confusion matrix ready, we will look into precision and recall, some important model evaluation metrics.</p>\n",
    "\n",
    "\n",
    " (1) <b>Accuracy</b> is simply the ratio of all correctly classified examples to all the examples. The accuracy measure is intuitive as good estimate of the performance of the model but it is not suited for an imbalanced classification problem which are quite common in everyday applications.\n",
    " \n",
    " $$\n",
    " Accuracy = \\frac{True Positives(TP) + True Negatives(TN)}{True Positives(TP) + True Negatives(TN) + False Positives(FP) + False Negatives(TN)}\n",
    " $$\n",
    "   <br>For example, if we have a spam classifier or a disease detection model where the disease rate is low. Suppose in such a problem we may get one or two spam mails or one or two postive patients as opposed to the hundreds of important mails we get or thousands of patients we scan for the disease. \n",
    "   <br>In such a case simple accuracy calculation is not a good evaluation strategy since we can get around 95-99% accuracy if we simply label every email as not spam or every patient as negative. But in these problems the positive example space is largely undermined by the more numerous negative examples, however we are more concerned with the performance on postive examples while the accuracy evaluation does not provide any insight into the problem. We turn to a more positive-example emphasizing measures of performance.\n",
    " \n",
    " \n",
    " (2) <b>Recall</b> is the ratio of the correctly identified positives to all the actual postives. It is the measure of the ability of the model to identify all the positive examples.\n",
    " \n",
    " $$\n",
    " Recall = \\frac{True Positives(TP)}{True Positives(TP) + False Negatives(FN)}\n",
    " $$\n",
    "<br>A recall value close to 1.00 is an indicator that the model identifies all the positive examples. But there is a caveat, if we know label each email as spam or each patient as diseased then we get a recall of 1 since we never a positive but the model is not actually classifying. By this reasoning we understand that maximizing recall alone cannot guarantee a good classifier. \n",
    "\n",
    " (3) <b>Precision</b> is the ratio of the correctly classified positive examples to all the examples that are either correctly or incorrectly classified as positives. \n",
    " \n",
    " $$\n",
    " Precision = \\frac{True Positives(TP)}{True Positives(TP) + False Positives(FP)}\n",
    " $$\n",
    " <br>The precision value is actually a measure of the ability of the model to correctly identify only the positive examples in the dataset. Together with recall, we can judge the performance of a classifier.\n",
    " <br>In other words, high precision guarantees that no negative examples will be flagged positive while a high recall guarantees all the positive examples will be flagged positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7583732057416268\n",
      "recall :  0.6708860759493671\n",
      "precision :  0.6838709677419355\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "print(\"accuracy : \", accuracy)\n",
    "#recall\n",
    "recall = tp/(tp+fn)\n",
    "print(\"recall : \", recall)\n",
    "#precision\n",
    "precision = tp/(tp+fp)\n",
    "print(\"precision : \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7583732057416268\n",
      "recall :  0.6708860759493671\n",
      "precision :  0.6838709677419355\n"
     ]
    }
   ],
   "source": [
    "# There are library functions in sklearn for precision, recall\n",
    "print(\"accuracy : \", measr.accuracy_score(Y_test, Y_pred))\n",
    "print(\"recall : \", measr.recall_score(Y_test, Y_pred))\n",
    "print(\"precision : \", measr.precision_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Precision-Recall Tradeoff and F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It is easy to see that our goal is a high precision-high recall model, that is, a model that correctly identifes all positives examples while not misjudging any negative example. This goal now prevents the earlier model where we flagged every mail as spam and every patient as diseased, since this model has a very low precision though the recall is high.</p>\n",
    "<p>Now on the contrary lets imagine a model that identifies just one positive example correctly. This has a high precision of 1.00 since it has not mislabelled any example as positive but it surely has missed a lot of positive examples and hence its recall is low.</p>\n",
    "<p>This is the crux of the <b>precision-recall tradeoff</b> that is observed very often in practice.\n",
    "Whether to emphasize more on high precision or high recall is dependent on the application an the result we desire. For example in the disease detection problem we may desire that no positive(diseased person) is left out and so we may focus on a high recall model than a precision model that misses out a few positve examples. In a spam classifier we may want a high precision model so that the user may not miss any important mail that was misclassified as a positive(spam) than a high recall model that classifies every spam email but may also classify your acceptance letter as spam ;(</p>\n",
    "<p>Most of the times, the problem may not require extremely high recall or precision, but a balanced maximization of both of them, we combine the two figures in a single performance metric called the <b>F1 Score</b>.</p>\n",
    "\n",
    "$$\n",
    "F1\\ Score = 2\\cdot\\frac{Precision \\times Recall}{Precision + Recall}\n",
    "$$\n",
    "<p>The F1 Score is the harmonic mean of the precision and recall that gives equal weightage to both precision and recall values and the modified goal is to maximize the F1 Score. The harmonic mean penalizes the extreme cases like precision = 1 and recall = 0 and vice versa, thus giving a balanced evaluation metric.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score(formulae) :  0.6773162939297125\n",
      "F1 Score(sklearn) :  0.6773162939297125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7f20284b1c70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#f1 score\n",
    "print(\"F1 Score(formulae) : \", (2 * precision * recall)/(precision + recall))\n",
    "# From sklearn.metrics library function\n",
    "print(\"F1 Score(sklearn) : \", measr.f1_score(Y_test, Y_pred))\n",
    "## An example of how precision and recall varies with respect to each other\n",
    "## where the tradeoff can be easily visualised.\n",
    "measr.plot_precision_recall_curve(logReg, X_test.T, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       260\n",
      "           1       0.68      0.67      0.68       158\n",
      "\n",
      "    accuracy                           0.76       418\n",
      "   macro avg       0.74      0.74      0.74       418\n",
      "weighted avg       0.76      0.76      0.76       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#everything in one go\n",
    "print(measr.classification_report(Y_test,Y_pred))\n",
    "##note: in the classification_report output there is precision and recall consider both 0 and 1 as a positive examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Precision and Recall in Multiclass Classification</h3>\n",
    "\n",
    "<p>The above definitions have been limited to a binary classifier model, but we can easily extend the definition of each of the above to a multiclass classifier model. We take an example of a 4-class classifier{0,1,2,3}</p>\n",
    "\n",
    "<p>The confusion matrix is then defined as $4\\times 4$ matrix $A = [a_{ij}]$ where $a_{ij}$ denotes the number of cases where the predicted class was i but the actual class was j where both $i,j\\in \\{0,1,2,3\\}$</p>\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Pred.</th>\n",
    "            <th>$0$</th>\n",
    "            <th>$1$</th>\n",
    "            <th>$2$</th>\n",
    "            <th>$3$</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>Actual</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> \n",
    "            <th>$0$</th>\n",
    "            <td>$a_{00}$</td>\n",
    "            <td>$a_{10}$</td>\n",
    "            <td>$a_{20}$</td>\n",
    "            <td>$a_{30}$</td>\n",
    "        </tr>\n",
    "        <tr> \n",
    "            <th>$1$</th>\n",
    "            <td>$a_{01}$</td>\n",
    "            <td>$a_{11}$</td>\n",
    "            <td>$a_{21}$</td>\n",
    "            <td>$a_{31}$</td>\n",
    "        </tr>\n",
    "         <tr> \n",
    "            <th>$2$</th>\n",
    "            <td>$a_{02}$</td>\n",
    "            <td>$a_{12}$</td>\n",
    "            <td>$a_{22}$</td>\n",
    "            <td>$a_{32}$</td>\n",
    "        </tr>\n",
    "         <tr> \n",
    "            <th>$3$</th>\n",
    "            <td>$a_{03}$</td>\n",
    "            <td>$a_{13}$</td>\n",
    "            <td>$a_{23}$</td>\n",
    "            <td>$a_{33}$</td>\n",
    "        </tr>\n",
    "    </tbody> \n",
    " </table> \n",
    " \n",
    "<p>Now we can define accuracy, recall and precision as a simple extension of the definitions we used above,\n",
    "<ul>\n",
    "    <li> Accuracy - truly identified examples divided by the total number of examples.\n",
    "    <li> Recall - ratio of truly identified positive examples (say category 0) to the actual number of category 0 examples.\n",
    "    <li> Precision - ratio of truly identified positive examples (category 0) to the all the predicted positives(category 0, here).\n",
    "</ul>\n",
    "$$\n",
    "Accuracy = \\frac{\\sum_{i=0}^{3} a_{ii}}{\\sum_{0\\leq i,j\\leq 3} a_{ij}}\n",
    "$$\n",
    "\n",
    "Note that any class can be considered as a positive example and precision and recall can be calculated from the confusion matrix.\n",
    "<p> For example, considering 0 as the positive class we can write the formulae for precision and recall as :</p>\n",
    "<hr>\n",
    "$$\n",
    "Recall = \\frac{a_{00}}{\\sum_{i=0}^{3} a_{i0}}\n",
    "$$\n",
    "<hr>\n",
    "$$\n",
    "Precision = \\frac{a_{00}}{\\sum_{i=0}^{3} a_{0i}}\n",
    "$$\n",
    "\n",
    "An easy way to get precision and recall is to print the classification report using the above sklearn.metrics function <em>classification_report</em> which calculates the values considering each class a positive turn by turn and then consider the actual positive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Precision or Recall</h3>\n",
    "    <p>We have seen how and why we calculate precision and recall. But how does it help you gain more insight about what your model is doing. Read on.</p>\n",
    "    <p>After having calculated Precision and Recall, one of the following may result:<P>\n",
    "    <ul>\n",
    "        <li><b>High Precision and High Recall</b> - By the definition of the quantities, we conclude that the model is able to correctly identify a significant percent of the positive example successfully without flagging false positives. This situation is generally the goal since the classifier model functions close to expected behavior - it identifies all positives and does not misidentify any negatives.</li>\n",
    "        <li><b>High Precision and Low Recall</b> - The classifier is able to identify positives very well but it does not identify all the examples present. In other words, it acts cautiously to not to flag any negative as positives but misses a significant amount of positives. We stress on the reducing false positives. Sometimes as noted in the above description a high precision is more important than recall; when you want to be sure that what we flag as positive is indeed positive although we may miss some positives. Like in a spam classifier, we want to label spam with high precision, since its okay if a few spammy mails enter the inbox but no important mail should be falsely labelled spam.</li>\n",
    "        <li><b>Low Precision and High Recall</b> - This is a dual of the above case, we get most of the positives although there may be a few negatives misclassified as positives. The concern is to identify all the positives, i.e., reducing false negatives. The model is more \"insecure\" in a sense it labels positives easily but none of the actual positives should be missed. A good examples is a terrorist detection system at an airport, we may want to check all the passengers with little suspicious activity even if they are not terrorists, so that we may not miss any positive(terrorist).</li>\n",
    "        <li><b>Low Precision and Low Recall</b> - This result implies that the model is not successful, its classification is neither precise nor it is able to flag all the positives. This result implies the model is not working well on the dataset and we need to improve the classification model.</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. Improving Precision and Recall</h3>\n",
    "<p> Ways to improve model precision : To increase the precision, we need to reduce the false positives. In a general sense, we need to make the criteria for being a positive more strict and fool-proof. To do this, we need to investigate the relationship of various data fields with respect to it being positive. We may remove unnecessary features in data that may be flagging false positives. </p>\n",
    "<p> To improve recall we need to again rummage with the features in the data, look closely to the relationship some feature has with actual positives and an include all these features.</p>\n",
    "<p> It almost never hurts to collect more data, especially about the positive values. More data will help the model better to explore relationships. Another way to try different classifiers like SVMs, K-Neighbors, Decision Trees, Random Forest, etc, or to change the architecture if using neural networks.</p>\n",
    "<p> Tuning hyperparamters like Lambda, Kernel type, etc can also be helpful in finding the optimal performance of the model</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The notion of precision and recall is not exactly intuitive like accuracy but in cases of imbalanced data like the few examples where one class of values are rarer, these serve to provide an insight into the performance of the model. ######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
